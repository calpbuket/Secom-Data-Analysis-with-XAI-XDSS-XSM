"""
SECOM Veri Seti - NÄ°HAÄ° FÄ°NAL PÄ°PELINE 
===========================================
Kalibrasyon Deneyi SonuÃ§larÄ±na GÃ¶re Optimize EdilmiÅŸ Versiyon

Kalibrasyon deneyinde test edilen 4 senaryo (Augmentation Yok, %10, %33, %50)
arasÄ±ndan %50 SMOTE + XGBoost en iyi performansÄ± gÃ¶sterdiÄŸi iÃ§in bu ayarlar
sabitlenmiÅŸtir.

Pipeline YapÄ±sÄ±:
    1. IterativeImputer (MICE) - Eksik veri tamamlama
    2. RobustScaler - Ã–zellik Ã¶lÃ§ekleme
    3. VarianceThreshold - DÃ¼ÅŸÃ¼k varyanslÄ± Ã¶zellik temizleme
    4. SMOTE (sampling_strategy=0.5) - AzÄ±nlÄ±k sÄ±nÄ±fÄ±nÄ± Ã§oÄŸunluÄŸun %50'sine Ã§Ä±kar
    5. XGBClassifier (scale_pos_weight otomatik)
    6. Threshold Optimizasyonu (F1-Score maksimizasyonu)

DeÄŸiÅŸiklikler (v1 â†’ v2):
     SMOTE oranÄ± 0.5 olarak sabitlendi (kalibrasyon deneyi sonucu)
     Brier Score eklendi (kalibrasyon metriÄŸi)
     Train/Val/Test metrikleri ayrÄ± ayrÄ± raporlanÄ±yor
"""

import warnings
warnings.filterwarnings('ignore')

import time
import random
import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.experimental import enable_iterative_imputer  # noqa
from sklearn.impute import IterativeImputer
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.metrics import (
    f1_score, recall_score, precision_score, roc_auc_score,
    precision_recall_curve, auc, confusion_matrix,
    classification_report, accuracy_score, brier_score_loss
)
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE

# =============================================================================
# GLOBAL SEED
# =============================================================================
RANDOM_SEED = 42

def set_all_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)

set_all_seeds(RANDOM_SEED)

# =============================================================================
# ğŸ”’ KALÄ°BRASYON DENEYÄ°NDEN GELEN SABÄ°TLER
# =============================================================================
SMOTE_RATIO = 0.5          # Kalibrasyon deneyi kazananÄ±: %50
BEST_MODEL = "XGBoost"     # TÃ¼m senaryolarda en iyi: XGBoost
VARIANCE_THRESHOLD = 0.01  # VarianceThreshold eÅŸiÄŸi

# =============================================================================
# YARDIMCI FONKSÄ°YONLAR
# =============================================================================

def calculate_missing_ratio(df):
    return df.isnull().sum() / len(df)


def drop_high_missing_columns(X, threshold=0.40):
    missing_ratios = calculate_missing_ratio(X)
    cols_to_drop = missing_ratios[missing_ratios >= threshold].index.tolist()
    X_clean = X.drop(columns=cols_to_drop)
    return X_clean, cols_to_drop


def drop_constant_columns(X):
    constant_cols = []
    for col in X.columns:
        nunique = X[col].dropna().nunique()
        std = X[col].std()
        if nunique <= 1 or (pd.notna(std) and std == 0):
            constant_cols.append(col)
    X_clean = X.drop(columns=constant_cols)
    return X_clean, constant_cols


def calculate_scale_pos_weight(y):
    """XGBoost iÃ§in scale_pos_weight deÄŸerini hesaplar."""
    n_negative = np.sum(y == 0)
    n_positive = np.sum(y == 1)
    if n_positive == 0:
        return 1.0
    return n_negative / n_positive


def pr_auc_score(y_true, y_prob):
    precision, recall, _ = precision_recall_curve(y_true, y_prob, pos_label=1)
    return auc(recall, precision)


def find_best_threshold(y_true, y_prob, metric='f1'):
    """
    F1-Score'u maksimize eden en iyi threshold'u bulur.

    Parameters:
    -----------
    y_true : array - GerÃ§ek etiketler
    y_prob : array - Tahmin olasÄ±lÄ±klarÄ±
    metric : str   - 'f1', 'recall', 'precision'

    Returns:
    --------
    best_threshold, best_score
    """
    thresholds = np.arange(0.01, 1.0, 0.01)
    scores = []

    for threshold in thresholds:
        y_pred = (y_prob >= threshold).astype(int)

        if metric == 'f1':
            score = f1_score(y_true, y_pred, pos_label=1, zero_division=0)
        elif metric == 'recall':
            score = recall_score(y_true, y_pred, pos_label=1, zero_division=0)
        elif metric == 'precision':
            score = precision_score(y_true, y_pred, pos_label=1, zero_division=0)
        else:
            score = f1_score(y_true, y_pred, pos_label=1, zero_division=0)

        scores.append(score)

    best_idx = np.argmax(scores)
    best_threshold = thresholds[best_idx]
    best_score = scores[best_idx]

    return best_threshold, best_score


# =============================================================================
# VERÄ° HAZIRLAMA
# =============================================================================

def load_and_prepare_data(filepath):
    print("=" * 70)
    print("VERÄ° HAZIRLAMA")
    print("=" * 70)

    df = pd.read_csv(filepath)
    print(f"\n[1] Veri yÃ¼klendi: {df.shape[0]} satÄ±r, {df.shape[1]} sÃ¼tun")

    if 'Time' in df.columns:
        df = df.drop(columns=['Time'])
        print("[2] 'Time' sÃ¼tunu drop edildi")

    y = df['Pass/Fail']
    X = df.drop(columns=['Pass/Fail'])
    print(f"[3] Hedef deÄŸiÅŸken ayrÄ±ldÄ±: {X.shape[1]} feature")

    X_clean, dropped_missing = drop_high_missing_columns(X, threshold=0.40)
    print(f"[4] %40+ eksik olan {len(dropped_missing)} sÃ¼tun drop edildi â†’ {X_clean.shape[1]} kaldÄ±")

    X_clean, dropped_constant = drop_constant_columns(X_clean)
    print(f"[5] Sabit {len(dropped_constant)} sÃ¼tun drop edildi â†’ {X_clean.shape[1]} kaldÄ±")

    y_encoded = (y == 1).astype(int)

    print(f"\n[6] SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
    print(f"    Pass (0): {(y_encoded == 0).sum()} ({(y_encoded == 0).mean()*100:.2f}%)")
    print(f"    Fail (1): {(y_encoded == 1).sum()} ({(y_encoded == 1).mean()*100:.2f}%)")

    return X_clean, y_encoded


# =============================================================================
# NÄ°HAÄ° FÄ°NAL PÄ°PELINE  DEÄERLENDÄ°RME
# =============================================================================

def evaluate_final_pipeline_v2(X, y):
    """
    Kalibrasyon deneyi sonuÃ§larÄ±na gÃ¶re optimize edilmiÅŸ pipeline:
    1. IterativeImputer
    2. RobustScaler
    3. VarianceThreshold
    4. SMOTE (sampling_strategy=0.5)  â† KALÄ°BRASYON DENEYÄ° SONUCU
    5. XGBoost (otomatik scale_pos_weight)
    6. Threshold Optimizasyonu
    """
    print("\n" + "=" * 70)
    print("NÄ°HAÄ° FÄ°NAL PÄ°PELINE DEÄERLENDÄ°RME")
    print("=" * 70)
    print("Kalibrasyon Deneyi SonuÃ§larÄ±na GÃ¶re Optimize EdilmiÅŸ:")
    print(f"  ğŸ”’ SMOTE oranÄ±: {SMOTE_RATIO:.0%} (azÄ±nlÄ±k â†’ Ã§oÄŸunluÄŸun %50'si)")
    print(f"  ğŸ”’ Model: {BEST_MODEL}")
    print("  âœ… scale_pos_weight otomatik (SMOTE sonrasÄ± daÄŸÄ±lÄ±ma gÃ¶re)")
    print("  âœ… Threshold Optimizasyonu (F1 maksimizasyonu)")
    print("  âœ… VarianceThreshold ile feature selection")
    print("  âœ… Brier Score ile kalibrasyon takibi")
    print("=" * 70)

    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)

    # Fold bazlÄ± skorlar
    fold_results = []
    all_y_true = []
    all_y_pred = []
    all_y_pred_default = []
    all_y_prob = []
    all_best_thresholds = []

    X_array = X.values if hasattr(X, 'values') else X
    y_array = y.values if hasattr(y, 'values') else y

    total_start = time.time()

    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_array, y_array)):
        fold_start = time.time()
        print(f"\n{'='*70}")
        print(f"FOLD {fold_idx + 1}/5")
        print(f"{'='*70}")

        X_train_full, X_test = X_array[train_idx], X_array[test_idx]
        y_train_full, y_test = y_array[train_idx], y_array[test_idx]

        # Train'i %80 train %20 validation'a bÃ¶l (threshold optimizasyonu iÃ§in)
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full,
            test_size=0.2,
            random_state=RANDOM_SEED,
            stratify=y_train_full
        )

        print(f"Veri bÃ¶lÃ¼nmesi:")
        print(f"  Train:      {len(y_train)} Ã¶rnek (Fail: {np.sum(y_train==1)})")
        print(f"  Validation: {len(y_val)} Ã¶rnek (Fail: {np.sum(y_val==1)})")
        print(f"  Test:       {len(y_test)} Ã¶rnek (Fail: {np.sum(y_test==1)})")

        # =================================================================
        # ADIM 1: IMPUTATION
        # =================================================================
        print(f"\n[1/6] IterativeImputer...", end=" ")
        imputer = IterativeImputer(
            estimator=ExtraTreesRegressor(n_estimators=10, random_state=RANDOM_SEED, n_jobs=-1),
            max_iter=10,
            random_state=RANDOM_SEED
        )
        X_train_imp = imputer.fit_transform(X_train)
        X_val_imp = imputer.transform(X_val)
        X_test_imp = imputer.transform(X_test)
        print("âœ“")

        # =================================================================
        # ADIM 2: SCALING
        # =================================================================
        print("[2/6] RobustScaler...", end=" ")
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train_imp)
        X_val_scaled = scaler.transform(X_val_imp)
        X_test_scaled = scaler.transform(X_test_imp)
        print("âœ“")

        # =================================================================
        # ADIM 3: VARIANCE THRESHOLD
        # =================================================================
        print("[3/6] VarianceThreshold...", end=" ")
        var_selector = VarianceThreshold(threshold=VARIANCE_THRESHOLD)
        X_train_selected = var_selector.fit_transform(X_train_scaled)
        X_val_selected = var_selector.transform(X_val_scaled)
        X_test_selected = var_selector.transform(X_test_scaled)
        n_features_removed = X_train_scaled.shape[1] - X_train_selected.shape[1]
        print(f"âœ“ ({n_features_removed} dÃ¼ÅŸÃ¼k varyanslÄ± Ã¶zellik kaldÄ±rÄ±ldÄ±)")

        # =================================================================
        # ADIM 4: SMOTE (sampling_strategy=0.5) â† KALÄ°BRASYON DENEYÄ°
        # =================================================================
        print("[4/6] SMOTE...", end=" ")

        n_majority = np.sum(y_train == 0)
        n_minority_current = np.sum(y_train == 1)
        n_minority_target = int(n_majority * SMOTE_RATIO)

        if n_minority_target <= n_minority_current:
            # Mevcut azÄ±nlÄ±k zaten yeterli - SMOTE uygulanmaz
            X_train_resampled = X_train_selected
            y_train_resampled = y_train
            print(f"âœ“ (Mevcut azÄ±nlÄ±k ({n_minority_current}) â‰¥ hedef ({n_minority_target}), SMOTE atlandÄ±)")
        else:
            smote = SMOTE(
                sampling_strategy={1: n_minority_target},
                random_state=RANDOM_SEED
            )
            X_train_resampled, y_train_resampled = smote.fit_resample(
                X_train_selected, y_train
            )
            n_new = n_minority_target - n_minority_current
            print(f"âœ“ (Fail: {n_minority_current} â†’ {n_minority_target}, +{n_new} sentetik Ã¶rnek)")

        print(f"  SMOTE sonrasÄ±: Fail={np.sum(y_train_resampled==1)}, "
              f"Pass={np.sum(y_train_resampled==0)}, "
              f"Oran={np.mean(y_train_resampled==1):.1%}")

        # =================================================================
        # ADIM 5: XGBoost (Otomatik scale_pos_weight)
        # =================================================================
        print("[5/6] XGBoost eÄŸitimi...", end=" ")

        scale_pos_weight = calculate_scale_pos_weight(y_train_resampled)
        print(f"\n  scale_pos_weight = {scale_pos_weight:.4f}")

        xgb_params = {
            'n_estimators': 100,
            'max_depth': 6,
            'learning_rate': 0.1,
            'scale_pos_weight': scale_pos_weight,
            'random_state': RANDOM_SEED,
            'n_jobs': -1,
            'eval_metric': 'logloss',
            'tree_method': 'hist'
        }

        model = XGBClassifier(**xgb_params)
        model.fit(X_train_resampled, y_train_resampled)
        print("  Model eÄŸitimi âœ“")

        # =================================================================
        # ADIM 6: THRESHOLD OPTÄ°MÄ°ZASYONU (Validation set Ã¼zerinde)
        # =================================================================
        print("[6/6] Threshold optimizasyonu...", end=" ")

        y_val_prob = model.predict_proba(X_val_selected)[:, 1]
        best_threshold, best_f1_val = find_best_threshold(y_val, y_val_prob, metric='f1')
        all_best_thresholds.append(best_threshold)

        print(f"âœ“")
        print(f"  En iyi threshold: {best_threshold:.3f} (Val F1: {best_f1_val:.4f})")

        # =================================================================
        # TAHMÄ°NLER VE METRÄ°KLER
        # =================================================================
        print("\nSonuÃ§lar:")

        # Train seti metrikleri (orijinal train, SMOTE'suz - overfitting kontrolÃ¼)
        y_train_prob = model.predict_proba(X_train_selected)[:, 1]
        y_train_pred_opt = (y_train_prob >= best_threshold).astype(int)
        brier_train = brier_score_loss(y_train, y_train_prob)

        # Validation seti metrikleri
        y_val_pred_opt = (y_val_prob >= best_threshold).astype(int)
        brier_val = brier_score_loss(y_val, y_val_prob)

        # Test seti metrikleri
        y_prob = model.predict_proba(X_test_selected)[:, 1]
        y_pred_default = model.predict(X_test_selected)
        y_pred_optimized = (y_prob >= best_threshold).astype(int)
        brier_test = brier_score_loss(y_test, y_prob)

        f1_default = f1_score(y_test, y_pred_default, pos_label=1, zero_division=0)
        recall_default = recall_score(y_test, y_pred_default, pos_label=1, zero_division=0)
        f1_optimized = f1_score(y_test, y_pred_optimized, pos_label=1, zero_division=0)
        recall_optimized = recall_score(y_test, y_pred_optimized, pos_label=1, zero_division=0)

        # Ekran Ã§Ä±ktÄ±sÄ±
        print(f"  {'Set':<12} {'F1_fail':>8} {'Recall':>8} {'Prec':>8} {'ROC-AUC':>9} {'Brier':>8}")
        print(f"  {'â”€'*55}")

        f1_tr = f1_score(y_train, y_train_pred_opt, pos_label=1, zero_division=0)
        rec_tr = recall_score(y_train, y_train_pred_opt, pos_label=1, zero_division=0)
        pre_tr = precision_score(y_train, y_train_pred_opt, pos_label=1, zero_division=0)
        auc_tr = roc_auc_score(y_train, y_train_prob)
        print(f"  {'Train':<12} {f1_tr:>8.4f} {rec_tr:>8.4f} {pre_tr:>8.4f} {auc_tr:>9.4f} {brier_train:>8.4f}")

        f1_v = f1_score(y_val, y_val_pred_opt, pos_label=1, zero_division=0)
        rec_v = recall_score(y_val, y_val_pred_opt, pos_label=1, zero_division=0)
        pre_v = precision_score(y_val, y_val_pred_opt, pos_label=1, zero_division=0)
        auc_v = roc_auc_score(y_val, y_val_prob)
        print(f"  {'Validation':<12} {f1_v:>8.4f} {rec_v:>8.4f} {pre_v:>8.4f} {auc_v:>9.4f} {brier_val:>8.4f}")

        pre_t = precision_score(y_test, y_pred_optimized, pos_label=1, zero_division=0)
        auc_t = roc_auc_score(y_test, y_prob)
        print(f"  {'Test':<12} {f1_optimized:>8.4f} {recall_optimized:>8.4f} {pre_t:>8.4f} {auc_t:>9.4f} {brier_test:>8.4f}")

        print(f"\n  Threshold karÅŸÄ±laÅŸtÄ±rma (Test):")
        print(f"    VarsayÄ±lan (0.5):       F1={f1_default:.4f}, Recall={recall_default:.4f}")
        print(f"    Optimize ({best_threshold:.3f}):   F1={f1_optimized:.4f}, Recall={recall_optimized:.4f}")
        print(f"    Ä°yileÅŸme:               F1 +{(f1_optimized - f1_default):.4f}, Recall +{(recall_optimized - recall_default):.4f}")

        # =================================================================
        # FOLD SONUÃ‡LARI
        # =================================================================
        fold_result = {
            'fold': fold_idx + 1,
            'best_threshold': best_threshold,
            # Train metrikleri
            'f1_fail_train': f1_tr,
            'recall_fail_train': rec_tr,
            'precision_fail_train': pre_tr,
            'roc_auc_train': auc_tr,
            'pr_auc_train': pr_auc_score(y_train, y_train_prob),
            'brier_train': brier_train,
            # Validation metrikleri
            'f1_fail_val': f1_v,
            'recall_fail_val': rec_v,
            'precision_fail_val': pre_v,
            'roc_auc_val': auc_v,
            'pr_auc_val': pr_auc_score(y_val, y_val_prob),
            'brier_val': brier_val,
            # Test metrikleri (optimize threshold)
            'accuracy': accuracy_score(y_test, y_pred_optimized),
            'f1_macro': f1_score(y_test, y_pred_optimized, average='macro'),
            'f1_fail': f1_optimized,
            'recall_fail': recall_optimized,
            'precision_fail': pre_t,
            'roc_auc': auc_t,
            'pr_auc': pr_auc_score(y_test, y_prob),
            'brier_test': brier_test,
            # KarÅŸÄ±laÅŸtÄ±rma (varsayÄ±lan threshold)
            'f1_fail_default': f1_default,
            'recall_fail_default': recall_default,
        }
        fold_results.append(fold_result)

        # Toplu deÄŸerlendirme iÃ§in
        all_y_true.extend(y_test)
        all_y_pred.extend(y_pred_optimized)
        all_y_pred_default.extend(y_pred_default)
        all_y_prob.extend(y_prob)

        fold_time = time.time() - fold_start
        print(f"\n  Fold sÃ¼resi: {fold_time:.1f}s")

    total_time = time.time() - total_start
    avg_threshold = np.mean(all_best_thresholds)

    print(f"\n{'='*70}")
    print(f"Ortalama En Ä°yi Threshold: {avg_threshold:.3f}")
    print(f"Toplam SÃ¼re: {total_time:.1f}s")
    print(f"{'='*70}")

    return (fold_results, np.array(all_y_true), np.array(all_y_pred),
            np.array(all_y_pred_default), np.array(all_y_prob), total_time, avg_threshold)


# =============================================================================
# SONUÃ‡ RAPORU
# =============================================================================

def generate_report(fold_results, y_true, y_pred, y_pred_default, y_prob, total_time, avg_threshold):
    """KapsamlÄ± sonuÃ§ raporu Ã¼ret."""

    print("\n" + "=" * 70)
    print("FÄ°NAL SONUÃ‡ RAPORU (Kalibrasyon Deneyi Optimize)")
    print("=" * 70)

    results_df = pd.DataFrame(fold_results)

    # 1. FOLD BAZLI SONUÃ‡LAR
    print("\n--- FOLD BAZLI SONUÃ‡LAR (Test Seti - Optimize EdilmiÅŸ Threshold) ---\n")
    display_cols = ['fold', 'best_threshold', 'f1_fail', 'recall_fail',
                    'precision_fail', 'brier_test', 'f1_fail_default', 'recall_fail_default']
    display_df = results_df[display_cols].copy()

    for col in display_df.columns:
        if col != 'fold':
            display_df[col] = display_df[col].apply(lambda x: f"{x:.4f}")
    print(display_df.to_string(index=False))

    # 2. Ã–ZET Ä°STATÄ°STÄ°KLER
    print("\n--- Ã–ZET Ä°STATÄ°STÄ°KLER (Mean Â± Std) ---\n")

    # Test metrikleri
    test_metrics = ['accuracy', 'f1_macro', 'f1_fail', 'recall_fail',
                    'precision_fail', 'roc_auc', 'pr_auc', 'brier_test']

    summary = {}
    print("Test Seti (Optimize EdilmiÅŸ Threshold ile):")
    for metric in test_metrics:
        mean_val = results_df[metric].mean()
        std_val = results_df[metric].std()
        summary[metric] = {'mean': mean_val, 'std': std_val}
        label = "Brier Score" if metric == 'brier_test' else metric
        print(f"  {label:<18}: {mean_val:.4f} Â± {std_val:.4f}")

    # Train vs Val vs Test karÅŸÄ±laÅŸtÄ±rma
    print("\n--- OVERFITTING KONTROLÃœ (F1_fail / Brier Score) ---\n")
    for split_name, f1_col, brier_col in [
        ('Train',      'f1_fail_train', 'brier_train'),
        ('Validation', 'f1_fail_val',   'brier_val'),
        ('Test',       'f1_fail',       'brier_test')
    ]:
        f1_mean = results_df[f1_col].mean()
        f1_std = results_df[f1_col].std()
        br_mean = results_df[brier_col].mean()
        br_std = results_df[brier_col].std()
        print(f"  {split_name:<12} F1_fail: {f1_mean:.4f} Â± {f1_std:.4f}  |  "
              f"Brier: {br_mean:.4f} Â± {br_std:.4f}")

    # Threshold karÅŸÄ±laÅŸtÄ±rma
    print("\nVarsayÄ±lan Threshold (0.5) ile karÅŸÄ±laÅŸtÄ±rma:")
    f1_default_mean = results_df['f1_fail_default'].mean()
    recall_default_mean = results_df['recall_fail_default'].mean()
    f1_improvement = summary['f1_fail']['mean'] - f1_default_mean
    recall_improvement = summary['recall_fail']['mean'] - recall_default_mean

    print(f"  F1-Score (Fail):    {f1_default_mean:.4f} â†’ {summary['f1_fail']['mean']:.4f} (+{f1_improvement:.4f})")
    print(f"  Recall (Fail):      {recall_default_mean:.4f} â†’ {summary['recall_fail']['mean']:.4f} (+{recall_improvement:.4f})")

    # 3. CONFUSION MATRIX
    print("\n--- CONFUSION MATRIX (Optimize EdilmiÅŸ Threshold) ---\n")
    cm_optimized = confusion_matrix(y_true, y_pred)
    tn_opt, fp_opt, fn_opt, tp_opt = cm_optimized.ravel()

    print(f"                 Predicted")
    print(f"                 Pass    Fail")
    print(f"  Actual Pass    {tn_opt:5d}   {fp_opt:5d}")
    print(f"  Actual Fail    {fn_opt:5d}   {tp_opt:5d}")

    cm_default = confusion_matrix(y_true, y_pred_default)
    tn_def, fp_def, fn_def, tp_def = cm_default.ravel()

    print("\n--- CONFUSION MATRIX (VarsayÄ±lan Threshold 0.5) ---\n")
    print(f"                 Predicted")
    print(f"                 Pass    Fail")
    print(f"  Actual Pass    {tn_def:5d}   {fp_def:5d}")
    print(f"  Actual Fail    {fn_def:5d}   {tp_def:5d}")

    print("\n--- KARÅILAÅTIRMA ---")
    print(f"  True Positives:  {tp_def} â†’ {tp_opt} (+{tp_opt - tp_def} hatalÄ± Ã¼rÃ¼n daha yakalandÄ±!)")
    print(f"  False Negatives: {fn_def} â†’ {fn_opt} ({fn_def - fn_opt} kaÃ§Ä±rÄ±lan hata azaldÄ±!)")
    print(f"  False Positives: {fp_def} â†’ {fp_opt} (+{fp_opt - fp_def} yanlÄ±ÅŸ alarm)")

    tpr = tp_opt / (tp_opt + fn_opt) if (tp_opt + fn_opt) > 0 else 0
    fpr = fp_opt / (fp_opt + tn_opt) if (fp_opt + tn_opt) > 0 else 0
    tnr = tn_opt / (tn_opt + fp_opt) if (tn_opt + fp_opt) > 0 else 0

    print(f"\n  Sensitivity (TPR/Recall): {tpr:.4f}")
    print(f"  Specificity (TNR):        {tnr:.4f}")
    print(f"  False Positive Rate:      {fpr:.4f}")

    # 4. CLASSIFICATION REPORT
    print("\n--- CLASSIFICATION REPORT (Optimize EdilmiÅŸ) ---\n")
    print(classification_report(y_true, y_pred, target_names=['Pass (0)', 'Fail (1)']))

    # 5. TOPLAM SÃœRE
    print(f"\n--- TOPLAM SÃœRE ---")
    print(f"  {total_time:.1f} saniye ({total_time/60:.1f} dakika)")

    return summary, cm_optimized, cm_default


def generate_thesis_summary(summary, cm_opt, cm_def, avg_threshold):
    """Tez iÃ§in hazÄ±r Ã¶zet metni Ã¼ret."""

    print("\n" + "=" * 70)
    print("TEZ Ä°Ã‡Ä°N Ã–ZET METÄ°N")
    print("=" * 70)

    tn_opt, fp_opt, fn_opt, tp_opt = cm_opt.ravel()
    tn_def, fp_def, fn_def, tp_def = cm_def.ravel()

    text = f"""
### Nihai Model PerformansÄ± (Kalibrasyon Deneyi SonrasÄ±)

SECOM yarÄ± iletken Ã¼retim veri seti Ã¼zerinde yapÄ±lan kalibrasyon deneyi
kapsamÄ±nda 4 farklÄ± veri artÄ±rÄ±m senaryosu (Augmentation Yok, %10, %33, %50)
ve 3 farklÄ± model (XGBoost, LightGBM, RandomForest) sistematik olarak
karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Brier Score ve Reliability Diagram analizleri
sonucunda en iyi kalibrasyon ve performans aÅŸaÄŸÄ±daki konfigÃ¼rasyonla
elde edilmiÅŸtir:

**Kazanan KonfigÃ¼rasyon:**
- Model: XGBoost
- SMOTE OranÄ±: %50 (azÄ±nlÄ±k sÄ±nÄ±fÄ± â†’ Ã§oÄŸunluÄŸun %50'si)

**Pipeline YapÄ±sÄ±:**
1. IterativeImputer (MICE) - Eksik veri tamamlama
2. RobustScaler - Ã–zellik Ã¶lÃ§ekleme
3. VarianceThreshold - DÃ¼ÅŸÃ¼k varyanslÄ± Ã¶zellik temizleme
4. SMOTE (sampling_strategy=0.5) - SÄ±nÄ±f dengesizliÄŸi dÃ¼zeltme
5. XGBClassifier (scale_pos_weight otomatik)
6. Threshold Optimizasyonu - F1-Score maksimizasyonu

**5-Fold Cross-Validation SonuÃ§larÄ±:**

| Metrik | Ortalama | Std |
|--------|----------|-----|
| F1-Score (Fail) | {summary['f1_fail']['mean']:.4f} | {summary['f1_fail']['std']:.4f} |
| Recall (Fail) | {summary['recall_fail']['mean']:.4f} | {summary['recall_fail']['std']:.4f} |
| Precision (Fail) | {summary['precision_fail']['mean']:.4f} | {summary['precision_fail']['std']:.4f} |
| ROC-AUC | {summary['roc_auc']['mean']:.4f} | {summary['roc_auc']['std']:.4f} |
| PR-AUC | {summary['pr_auc']['mean']:.4f} | {summary['pr_auc']['std']:.4f} |
| Brier Score | {summary['brier_test']['mean']:.4f} | {summary['brier_test']['std']:.4f} |

**Threshold Optimizasyonu Etkisi:**
- VarsayÄ±lan (0.5) â†’ Optimize ({avg_threshold:.3f})
- Yakalanan HatalÄ± ÃœrÃ¼n: {tp_def} â†’ {tp_opt} (+{tp_opt - tp_def} âœ…)
- KaÃ§Ä±rÄ±lan Hata: {fn_def} â†’ {fn_opt} (-{fn_def - fn_opt} âœ…)
- YanlÄ±ÅŸ Alarm: {fp_def} â†’ {fp_opt} (+{fp_opt - fp_def})

**Kalibrasyon Deneyi Ã–nemli BulgularÄ±:**
- SMOTE artÄ±rÄ±m oranÄ± arttÄ±kÃ§a modelin azÄ±nlÄ±k sÄ±nÄ±fÄ±nÄ± (Fail) tanÄ±ma
  yeteneÄŸi iyileÅŸmektedir.
- %50 oranÄ±, Recall ve F1 dengesini en iyi saÄŸlayan noktadÄ±r.
- XGBoost, gradient boosting ailesi iÃ§inde en tutarlÄ± performansÄ±
  sergilemiÅŸtir.
- Brier Score ile doÄŸrulanan kalibrasyon, modelin Ã¼rettiÄŸi olasÄ±lÄ±k
  tahminlerinin gÃ¼venilir olduÄŸunu gÃ¶stermektedir.

**Yorum:**
Threshold optimizasyonu sayesinde, model {tp_opt - tp_def} adet daha fazla
hatalÄ± Ã¼rÃ¼nÃ¼ tespit edebilmektedir. Bu, Ã¼retim hattÄ±nda kalite kontrol
maliyetlerini Ã¶nemli Ã¶lÃ§Ã¼de azaltabilir. Recall deÄŸeri
{summary['recall_fail']['mean']:.2%} olup, hatalÄ± Ã¼rÃ¼nlerin
{summary['recall_fail']['mean']*100:.0f}/100'Ã¼nÃ¼n yakalanabildiÄŸini
gÃ¶stermektedir.
"""

    print(text)
    return text


# =============================================================================
# ANA FONKSÄ°YON
# =============================================================================

def main(filepath='secom.csv'):
    print("\n")
    print("*" * 70)
    print("  SECOM - NÄ°HAÄ° FÄ°NAL PÄ°PELINE")
    print("  Kalibrasyon Deneyi SonuÃ§larÄ±na GÃ¶re Optimize EdilmiÅŸ")
    print(f"  SMOTE={SMOTE_RATIO:.0%} + XGBoost + Threshold Optimizasyonu")
    print("*" * 70)

    # 1. Veri hazÄ±rlama
    X_clean, y = load_and_prepare_data(filepath)

    # 2. Pipeline deÄŸerlendirme
    (fold_results, y_true, y_pred, y_pred_default,
     y_prob, total_time, avg_threshold) = evaluate_final_pipeline_v2(X_clean, y)

    # 3. Rapor Ã¼ret
    summary, cm_opt, cm_def = generate_report(
        fold_results, y_true, y_pred, y_pred_default, y_prob, total_time, avg_threshold
    )

    # 4. Tez Ã¶zeti
    thesis_text = generate_thesis_summary(summary, cm_opt, cm_def, avg_threshold)

    # 5. SonuÃ§larÄ± kaydet
    results_df = pd.DataFrame(fold_results)
    results_df.to_csv('secom_final_pipeline_results.csv', index=False)

    summary_df = pd.DataFrame([
        {'metric': k, 'mean': v['mean'], 'std': v['std']}
        for k, v in summary.items()
    ])
    summary_df.to_csv('secom_final_pipeline_summary.csv', index=False)

    # Tez metnini de kaydet
    with open('secom_thesis_summary.md', 'w', encoding='utf-8') as f:
        f.write(thesis_text)

    print("\n" + "=" * 70)
    print("[âœ“] SonuÃ§lar kaydedildi:")
    print("    - secom_final_pipeline_results.csv (fold bazlÄ±)")
    print("    - secom_final_pipeline_summary.csv (Ã¶zet)")
    print("    - secom_thesis_summary.md (tez Ã¶zet metni)")
    print("=" * 70)

    return fold_results, summary, cm_opt, cm_def, avg_threshold


# =============================================================================
# Ã‡ALIÅTIR
# =============================================================================

if __name__ == "__main__":
    filepath = "Buket/uci-secom.csv"

    results, summary, cm_opt, cm_def, avg_threshold = main(filepath)