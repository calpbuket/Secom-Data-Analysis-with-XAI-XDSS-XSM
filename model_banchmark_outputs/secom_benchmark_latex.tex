
\begin{table}[htbp]
\centering
\caption{Model Karşılaştırma Sonuçları}
\label{tab:model_benchmark}
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{F1$_{fail}$} & \textbf{Recall} & \textbf{Precision} & \textbf{PR-AUC} & \textbf{ROC-AUC} & \textbf{Süre(s)} \\
\midrule
LogisticRegression & 0.2499 & 0.5676 & 0.1621 & 0.1903 & 0.7153 & 32.7 \\
NaiveBayes & 0.2088 & 0.6143 & 0.1272 & 0.1753 & 0.6939 & 30.5 \\
RandomForest & 0.2747 & 0.5581 & 0.1830 & 0.2075 & 0.7640 & 34.2 \\
GradientBoosting & 0.2686 & 0.2695 & 0.2736 & 0.2002 & 0.7429 & 76.5 \\
XGBoost & 0.2196 & 0.2500 & 0.1973 & 0.2107 & 0.7301 & 32.6 \\
LightGBM & 0.2377 & 0.2500 & 0.2415 & 0.2160 & 0.7268 & 31.2 \\

\bottomrule
\end{tabular}
\end{table}
