"""
================================================================================
XSM INTERLOCK (OVERRIDE GATE)
X-HARMONY Mimarisi - GÃœVENLÄ°K KÄ°LÄ°DÄ° MEKANÄ°ZMASI
================================================================================

TEZ BAÅžLIÄžI: 4.5.3 - XSM Safety Interlock (GÃ¼venlik Kilidi MekanizmasÄ±)

Bu modÃ¼l, OperatÃ¶r-XDSS Ã§atÄ±ÅŸmasÄ± tespit edildiÄŸinde devreye girer ve
Ã§ok boyutlu risk analizi yaparak Ã¼Ã§ seviyeli gÃ¼venlik kararÄ± verir.

GÃœVENLÄ°K KararlarÄ± (Interlock Decisions):
    - ALLOW: OperatÃ¶r kararÄ±na izin ver (risk kabul edilebilir)
    - DENY: OperatÃ¶r engellenir, XDSS Ã¶nerisi zorlanÄ±r (yÃ¼ksek risk)
    - ESCALATE: Ä°kinci kontrol gerekli (supervisor/manual review)

Risk Analiz BileÅŸenleri:
    1. Model GÃ¼venilirlik Skoru (Model Confidence)
       - Tahmin olasÄ±lÄ±ÄŸÄ±
       - Model kalibrasyon durumu
    
    2. XAI Belirsizlik Skoru (XAI Uncertainty)
       - SHAP deÄŸer varyansÄ±
       - AÃ§Ä±klama tutarlÄ±lÄ±ÄŸÄ±
       - Feature importance entropi
    
    3. OperatÃ¶r Performans Skoru (Operator Track Record)
       - GeÃ§miÅŸ baÅŸarÄ± oranÄ±
       - Deneyim seviyesi
       - Benzer senaryolarda performans
    
    4. Sistem Drift/Anomali Skoru
       - Data distribution shift
       - SensÃ¶r anomalileri
       - Model drift gÃ¶stergeleri

Final Risk Score: AÄŸÄ±rlÄ±klÄ± kombinasyon (0-1)
Decision Logic: Risk skoruna gÃ¶re threshold-based karar

Yazar: X-HARMONY Implementation - Thesis Chapter 4.5.3
================================================================================
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Literal
from enum import Enum
from scipy import stats as scipy_stats


class InterlockDecision(Enum):
    """XSM Interlock kararlarÄ±."""
    ALLOW = "allow"           # OperatÃ¶r kararÄ±na izin
    DENY = "deny"             # OperatÃ¶r engellendi
    ESCALATE = "escalate"     # YÃ¼kselt (supervisor review)


class XSMInterlock:
    """
    XSM Safety Interlock - GÃ¼venlik Kilidi MekanizmasÄ±.
    
    TEZ 4.5.3: Bu modÃ¼l Ã§atÄ±ÅŸma durumunda Ã§ok boyutlu risk analizi
    yaparak operatÃ¶r kararÄ±nÄ±n yÃ¼rÃ¼tÃ¼lmesine izin verir veya engeller.
    """
    
    def __init__(
        self,
        risk_thresholds: Optional[Dict[str, float]] = None,
        verbose: bool = True
    ):
        """
        XSM Interlock'u baÅŸlat.
        
        Args:
            risk_thresholds: Risk eÅŸikleri (opsiyonel, varsayÄ±lan kullanÄ±lÄ±r)
            verbose: DetaylÄ± Ã§Ä±ktÄ±
        """
        self.verbose = verbose
        
        # Risk eÅŸikleri
        self.thresholds = risk_thresholds or self._default_thresholds()
        
        # Karar geÃ§miÅŸi
        self.interlock_history = []
        
        # AÄŸÄ±rlÄ±klar (risk bileÅŸenleri)
        self.risk_weights = {
            'model_confidence': 0.30,
            'xai_uncertainty': 0.25,
            'operator_performance': 0.25,
            'system_drift': 0.20
        }
        
        if self.verbose:
            print("=" * 70)
            print("XSM INTERLOCK (GÃœVENLÄ°K KÄ°LÄ°DÄ°) BAÃ…Å¾LATILDI (TEZ 4.5.3)")
            print("=" * 70)
            print("âœ“ Ã‡ok boyutlu risk analiz motoru aktif")
            print(f"âœ“ Risk aÄŸÄ±rlÄ±klarÄ±: {self.risk_weights}")
            print(f"âœ“ Karar eÅŸikleri: ALLOW<{self.thresholds['allow_max']:.2f}, "
                  f"DENY>{self.thresholds['deny_min']:.2f}")
            print("=" * 70)
    
    def _default_thresholds(self) -> Dict[str, float]:
        """
        VarsayÄ±lan risk eÅŸiklerini ayarla.
        
        TEZ: Bu eÅŸikler gÃ¼venlik-verimlilik dengesini belirler.
        Daha dÃ¼ÅŸÃ¼k allow_max = daha muhafazakar sistem
        """
        return {
            'allow_max': 0.35,      # Risk < 0.35 â†’ ALLOW
            'deny_min': 0.65,       # Risk > 0.65 â†’ DENY
            'escalate_range': (0.35, 0.65),  # 0.35-0.65 arasÄ± â†’ ESCALATE
            
            # Alt bileÅŸen eÅŸikleri
            'model_conf_critical': 0.3,    # Model gÃ¼veni < 0.3 â†’ kritik
            'xai_uncertainty_high': 0.7,    # XAI belirsizliÄŸi > 0.7 â†’ yÃ¼ksek
            'operator_acc_low': 0.7,        # OperatÃ¶r baÅŸarÄ± < 0.7 â†’ dÃ¼ÅŸÃ¼k
            'drift_critical': 0.8           # Drift > 0.8 â†’ kritik
        }
    
    def interlock_decision(
        self,
        conflict_report: Dict,
        model_prob: float,
        xdss_confidence: float,
        operator_profile: Dict,
        shap_values: np.ndarray,
        feature_values: np.ndarray,
        xsm_anomaly_report: Optional[Dict] = None
    ) -> Dict:
        """
        XSM Interlock kararÄ±nÄ± ver.
        
        TEZ 4.5.3: Bu fonksiyon Ã§atÄ±ÅŸma durumunda risk analizi yaparak
        operatÃ¶r kararÄ±nÄ±n yÃ¼rÃ¼tÃ¼lmesine izin verir veya engeller.
        
        Args:
            conflict_report: Conflict Detector'dan gelen rapor
            model_prob: Model fail olasÄ±lÄ±ÄŸÄ± (0-1)
            xdss_confidence: XDSS gÃ¼ven skoru
            operator_profile: OperatÃ¶r profil bilgileri
            shap_values: SHAP aÃ§Ä±klama deÄŸerleri
            feature_values: SensÃ¶r deÄŸerleri
            xsm_anomaly_report: XSM anomali raporu (opsiyonel)
            
        Returns:
            interlock_report: {
                'decision': InterlockDecision,
                'risk_score': float,
                'risk_breakdown': Dict,
                'reasoning': str,
                'final_action': str,
                'confidence': float
            }
        """
        
        # Ã‡atÄ±ÅŸma yoksa interlock gerekmez
        if not conflict_report['conflict_flag']:
            return {
                'decision': InterlockDecision.ALLOW,
                'risk_score': 0.0,
                'risk_breakdown': {},
                'reasoning': "Ã‡atÄ±ÅŸma tespit edilmedi. Interlock gerekli deÄŸil.",
                'final_action': conflict_report['operator_action'],
                'confidence': 1.0,
                'interlock_triggered': False
            }
        
        # 1. Ã‡ok boyutlu risk analizi
        risk_breakdown = self._comprehensive_risk_analysis(
            model_prob=model_prob,
            xdss_confidence=xdss_confidence,
            operator_profile=operator_profile,
            shap_values=shap_values,
            feature_values=feature_values,
            xsm_anomaly_report=xsm_anomaly_report,
            conflict_severity=conflict_report['severity']
        )
        
        # 2. Final risk skorunu hesapla
        final_risk_score = self._calculate_final_risk_score(risk_breakdown)
        
        # 3. Karar ver (ALLOW / DENY / ESCALATE)
        interlock_decision, decision_confidence = self._make_interlock_decision(
            final_risk_score, risk_breakdown
        )
        
        # 4. Final aksiyonu belirle
        final_action = self._determine_final_action(
            interlock_decision,
            conflict_report['operator_action'],
            conflict_report['xdss_action']
        )
        
        # 5. GerekÃ§e Ã¼ret
        reasoning = self._generate_reasoning(
            interlock_decision, final_risk_score,
            risk_breakdown, conflict_report
        )
        
        # Rapor oluÅŸtur
        interlock_report = {
            'decision': interlock_decision,
            'risk_score': final_risk_score,
            'risk_breakdown': risk_breakdown,
            'reasoning': reasoning,
            'final_action': final_action,
            'confidence': decision_confidence,
            'interlock_triggered': True,
            'conflict_summary': {
                'xdss_action': conflict_report['xdss_action'],
                'operator_action': conflict_report['operator_action'],
                'conflict_severity': conflict_report['severity'].value
            }
        }
        
        # GeÃ§miÃ…Å¸e kaydet
        self.interlock_history.append(interlock_report)
        
        return interlock_report
    
    def _comprehensive_risk_analysis(
        self,
        model_prob: float,
        xdss_confidence: float,
        operator_profile: Dict,
        shap_values: np.ndarray,
        feature_values: np.ndarray,
        xsm_anomaly_report: Optional[Dict],
        conflict_severity: Enum
    ) -> Dict:
        """
        Ã‡ok boyutlu risk analizi.
        
        TEZ: Bu fonksiyon 4 ana risk bileÅŸenini hesaplar:
        1. Model GÃ¼venilirliÄŸi
        2. XAI BelirsizliÄŸi
        3. OperatÃ¶r PerformansÄ±
        4. Sistem Drift/Anomali
        """
        
        risk_breakdown = {}
        
        # 1. MODEL GÃœVENÄ°LÄ°RLÄ°K SKORU
        risk_breakdown['model_confidence'] = self._assess_model_reliability(
            model_prob, xdss_confidence
        )
        
        # 2. XAI BELÄ°RSÄ°ZLÄ°K SKORU
        risk_breakdown['xai_uncertainty'] = self._assess_xai_uncertainty(
            shap_values, feature_values
        )
        
        # 3. OPERATÃ–R PERFORMANS SKORU
        risk_breakdown['operator_performance'] = self._assess_operator_performance(
            operator_profile
        )
        
        # 4. SÄ°STEM DRIFT/ANOMALÄ° SKORU
        risk_breakdown['system_drift'] = self._assess_system_drift(
            xsm_anomaly_report, feature_values
        )
        
        # 5. Ã‡ATIÅžMA ÅžÄ°DDETÄ° ETKÄ°SÄ°
        risk_breakdown['conflict_severity_impact'] = self._assess_conflict_impact(
            conflict_severity
        )
        
        return risk_breakdown
    
    def _assess_model_reliability(
        self, 
        model_prob: float,
        xdss_confidence: float
    ) -> Dict:
        """
        Model gÃ¼venilirlik riskini deÄŸerlendir.
        
        TEZ: YÃ¼ksek model gÃ¼veni + yÃ¼ksek XDSS gÃ¼veni = dÃ¼ÅŸÃ¼k risk
        """
        
        # Model kesinliÄŸi (0.5'ten uzaklÄ±k)
        model_certainty = abs(model_prob - 0.5) * 2  # 0-1 normalize
        
        # XDSS gÃ¼veni
        xdss_certainty = xdss_confidence
        
        # BirleÅŸik gÃ¼venilirlik (yÃ¼ksek = gÃ¼venilir = dÃ¼ÅŸÃ¼k risk)
        reliability = (model_certainty + xdss_certainty) / 2
        
        # Risk skoru (1 - gÃ¼venilirlik)
        risk_score = 1 - reliability
        
        return {
            'risk_score': risk_score,
            'model_certainty': model_certainty,
            'xdss_certainty': xdss_certainty,
            'overall_reliability': reliability,
            'interpretation': (
                "YÃ¼ksek gÃ¼venilirlik" if reliability > 0.7 else
                "Orta gÃ¼venilirlik" if reliability > 0.4 else
                "DÃ¼ÅŸÃ¼k gÃ¼venilirlik"
            )
        }
    
    def _assess_xai_uncertainty(
        self,
        shap_values: np.ndarray,
        feature_values: np.ndarray
    ) -> Dict:
        """
        XAI belirsizlik riskini deÄŸerlendir.
        
        TEZ: SHAP deÄŸerlerinin tutarlÄ±lÄ±ÄŸÄ± ve daÄŸÄ±lÄ±mÄ±.
        YÃ¼ksek belirsizlik = aÃ§Ä±klama gÃ¼venilmez = yÃ¼ksek risk
        """
        
        # 1. SHAP varyansÄ± (normalize edilmiÅŸ)
        shap_variance = np.var(shap_values) if len(shap_values) > 0 else 0
        shap_variance_norm = min(shap_variance / 0.1, 1.0)  # 0.1'e normalize
        
        # 2. SHAP entropy (daÄŸÄ±lÄ±m belirsizliÄŸi)
        # Pozitif SHAP deÄŸerlerinin daÄŸÄ±lÄ±mÄ±
        pos_shap = shap_values[shap_values > 0]
        if len(pos_shap) > 0:
            # Normalize et
            pos_shap_norm = pos_shap / (np.sum(np.abs(pos_shap)) + 1e-10)
            entropy = scipy_stats.entropy(pos_shap_norm + 1e-10)
            entropy_norm = min(entropy / 3.0, 1.0)  # 3.0'a normalize
        else:
            entropy_norm = 0.5  # Orta belirsizlik
        
        # 3. SHAP sparsity (Ã§ok az feature etkili mi?)
        sparsity = np.sum(np.abs(shap_values) < 0.01) / len(shap_values)
        
        # 4. Top SHAP dominance (tek bir feature Ã§ok baskÄ±n mÄ±?)
        if len(shap_values) > 0:
            top_shap = np.max(np.abs(shap_values))
            total_shap = np.sum(np.abs(shap_values))
            dominance = top_shap / (total_shap + 1e-10) if total_shap > 0 else 0
        else:
            dominance = 0
        
        # BirleÅŸik belirsizlik skoru
        uncertainty_score = (
            shap_variance_norm * 0.3 +
            entropy_norm * 0.3 +
            sparsity * 0.2 +
            dominance * 0.2
        )
        
        return {
            'risk_score': uncertainty_score,
            'shap_variance': float(shap_variance),
            'entropy': float(entropy_norm),
            'sparsity': float(sparsity),
            'dominance': float(dominance),
            'interpretation': (
                "YÃ¼ksek belirsizlik" if uncertainty_score > 0.7 else
                "Orta belirsizlik" if uncertainty_score > 0.4 else
                "DÃ¼ÅŸÃ¼k belirsizlik"
            )
        }
    
    def _assess_operator_performance(
        self,
        operator_profile: Dict
    ) -> Dict:
        """
        OperatÃ¶r performans riskini deÄŸerlendir.
        
        TEZ: YÃ¼ksek deneyim + yÃ¼ksek baÅŸarÄ± oranÄ± = dÃ¼ÅŸÃ¼k risk
        """
        
        # OperatÃ¶r Ã¶zellikleri
        experience_years = operator_profile.get('experience_years', 3.0)
        historical_accuracy = operator_profile.get('historical_accuracy', 0.75)
        
        # Deneyim skoru (0-1, 10+ yÄ±l = 1.0)
        experience_score = min(experience_years / 10.0, 1.0)
        
        # BaÅŸarÄ± skoru (0-1)
        accuracy_score = historical_accuracy
        
        # BirleÅŸik performans (yÃ¼ksek = iyi = dÃ¼ÅŸÃ¼k risk)
        performance = (experience_score + accuracy_score) / 2
        
        # Risk skoru (1 - performans)
        risk_score = 1 - performance
        
        return {
            'risk_score': risk_score,
            'experience_score': experience_score,
            'accuracy_score': accuracy_score,
            'overall_performance': performance,
            'interpretation': (
                "YÃ¼ksek performans" if performance > 0.75 else
                "Orta performans" if performance > 0.5 else
                "DÃ¼ÅŸÃ¼k performans"
            )
        }
    
    def _assess_system_drift(
        self,
        xsm_anomaly_report: Optional[Dict],
        feature_values: np.ndarray
    ) -> Dict:
        """
        Sistem drift/anomali riskini deÄŸerlendir.
        
        TEZ: Veri daÄŸÄ±lÄ±mÄ± kaymasÄ± ve anomaliler.
        YÃ¼ksek drift = sistem gÃ¼venilmez = yÃ¼ksek risk
        """
        
        # XSM raporu varsa kullan
        if xsm_anomaly_report:
            anomaly_count = len(xsm_anomaly_report.get('anomalies', []))
            status = xsm_anomaly_report.get('status', 'NORMAL')
            
            # Status'e gÃ¶re risk
            status_risk = {
                'NORMAL': 0.1,
                'WARNING': 0.4,
                'INFO': 0.2,
                'CRITICAL': 0.9
            }.get(status, 0.3)
            
            # Anomali sayÄ±sÄ±na gÃ¶re risk
            anomaly_risk = min(anomaly_count * 0.15, 0.8)
            
            drift_score = (status_risk + anomaly_risk) / 2
        
        else:
            # Basit outlier tespiti
            extreme_values = np.sum(np.abs(feature_values) > 3.0)
            drift_score = min(extreme_values * 0.1, 0.6)
        
        return {
            'risk_score': drift_score,
            'interpretation': (
                "YÃ¼ksek drift" if drift_score > 0.7 else
                "Orta drift" if drift_score > 0.4 else
                "DÃ¼ÅŸÃ¼k drift"
            )
        }
    
    def _assess_conflict_impact(self, conflict_severity: Enum) -> Dict:
        """Ã‡atÄ±ÅŸma ÅŸiddetinin risk etkisi."""
        
        severity_scores = {
            'none': 0.0,
            'low': 0.2,
            'moderate': 0.5,
            'critical': 0.9
        }
        
        severity_value = conflict_severity.value if hasattr(conflict_severity, 'value') else 'moderate'
        risk_score = severity_scores.get(severity_value, 0.5)
        
        return {
            'risk_score': risk_score,
            'severity': severity_value
        }
    
    def _calculate_final_risk_score(self, risk_breakdown: Dict) -> float:
        """
        Final risk skorunu hesapla (aÄŸÄ±rlÄ±klÄ± kombinasyon).
        
        TEZ: TÃ¼m risk bileÅŸenlerini aÄŸÄ±rlÄ±klÄ± olarak birleÅŸtir.
        """
        
        final_score = (
            risk_breakdown['model_confidence']['risk_score'] * self.risk_weights['model_confidence'] +
            risk_breakdown['xai_uncertainty']['risk_score'] * self.risk_weights['xai_uncertainty'] +
            risk_breakdown['operator_performance']['risk_score'] * self.risk_weights['operator_performance'] +
            risk_breakdown['system_drift']['risk_score'] * self.risk_weights['system_drift']
        )
        
        # Ã‡atÄ±ÅŸma ÅŸiddeti bonus
        conflict_impact = risk_breakdown['conflict_severity_impact']['risk_score']
        final_score = min(final_score + conflict_impact * 0.15, 1.0)
        
        return final_score
    
    def _make_interlock_decision(
        self,
        risk_score: float,
        risk_breakdown: Dict
    ) -> Tuple[InterlockDecision, float]:
        """
        Risk skoruna gÃ¶re interlock kararÄ± ver.
        
        TEZ: Threshold-based karar mantÄ±ÄŸÄ±.
        """
        
        # ALLOW: DÃ¼ÅŸÃ¼k risk â†’ OperatÃ¶r kararÄ±na izin
        if risk_score < self.thresholds['allow_max']:
            decision = InterlockDecision.ALLOW
            confidence = 1 - risk_score  # DÃ¼ÅŸÃ¼k risk = yÃ¼ksek gÃ¼ven
        
        # DENY: YÃ¼ksek risk â†’ OperatÃ¶r engellendi
        elif risk_score > self.thresholds['deny_min']:
            decision = InterlockDecision.DENY
            confidence = risk_score  # YÃ¼ksek risk = DENY'a yÃ¼ksek gÃ¼ven
        
        # ESCALATE: Orta risk â†’ Ä°kinci kontrol
        else:
            decision = InterlockDecision.ESCALATE
            # Orta bÃ¶lgede gÃ¼ven daha dÃ¼ÅŸÃ¼k
            confidence = 0.6
        
        return decision, confidence
    
    def _determine_final_action(
        self,
        decision: InterlockDecision,
        operator_action: str,
        xdss_action: str
    ) -> str:
        """
        Final aksiyonu belirle.
        
        TEZ: Interlock kararÄ±na gÃ¶re hangi aksiyon yÃ¼rÃ¼tÃ¼lecek.
        """
        
        if decision == InterlockDecision.ALLOW:
            # OperatÃ¶r kararÄ± yÃ¼rÃ¼tÃ¼lÃ¼r
            return operator_action
        
        elif decision == InterlockDecision.DENY:
            # XDSS Ã¶nerisi zorlanÄ±r
            return xdss_action
        
        else:  # ESCALATE
            # En gÃ¼venli seÃ§enek (genelde XDSS)
            # veya Ã¶zel bir escalation aksiyonu
            return "ESCALATE_TO_SUPERVISOR"
    
    def _generate_reasoning(
        self,
        decision: InterlockDecision,
        risk_score: float,
        risk_breakdown: Dict,
        conflict_report: Dict
    ) -> str:
        """
        Karar gerekÃ§esini Ã¼ret.
        
        TEZ: Åžeffaf ve aÃ§Ä±klanabilir karar mantÄ±ÄŸÄ±.
        """
        
        reasoning = f"XSM Interlock KararÄ±: {decision.value.upper()}\n"
        reasoning += f"Final Risk Skoru: {risk_score:.3f}\n\n"
        
        reasoning += "Risk Analizi:\n"
        reasoning += f"  1. Model GÃ¼venilirliÄŸi: {risk_breakdown['model_confidence']['risk_score']:.3f} "
        reasoning += f"({risk_breakdown['model_confidence']['interpretation']})\n"
        
        reasoning += f"  2. XAI BelirsizliÄŸi: {risk_breakdown['xai_uncertainty']['risk_score']:.3f} "
        reasoning += f"({risk_breakdown['xai_uncertainty']['interpretation']})\n"
        
        reasoning += f"  3. OperatÃ¶r PerformansÄ±: {risk_breakdown['operator_performance']['risk_score']:.3f} "
        reasoning += f"({risk_breakdown['operator_performance']['interpretation']})\n"
        
        reasoning += f"  4. Sistem Drift: {risk_breakdown['system_drift']['risk_score']:.3f} "
        reasoning += f"({risk_breakdown['system_drift']['interpretation']})\n"
        
        reasoning += f"\nKarar MantÄ±ÄŸÄ±:\n"
        
        if decision == InterlockDecision.ALLOW:
            reasoning += f"  â€¢ Risk kabul edilebilir seviyede ({risk_score:.3f} < {self.thresholds['allow_max']})\n"
            reasoning += f"  â€¢ OperatÃ¶r kararÄ± ({conflict_report['operator_action']}) yÃ¼rÃ¼tÃ¼lÃ¼r\n"
        
        elif decision == InterlockDecision.DENY:
            reasoning += f"  â€¢ Risk Ã§ok yÃ¼ksek ({risk_score:.3f} > {self.thresholds['deny_min']})\n"
            reasoning += f"  â€¢ OperatÃ¶r kararÄ± ENGELLENDÄ° âœ˜\n"
            reasoning += f"  â€¢ XDSS Ã¶nerisi ({conflict_report['xdss_action']}) ZORLANDI\n"
        
        else:  # ESCALATE
            reasoning += f"  â€¢ Risk orta seviyede (belirsizlik bÃ¶lgesi)\n"
            reasoning += f"  â€¢ Supervisor/manual review gerekli\n"
            reasoning += f"  â€¢ Ãœretim gÃ¼venli moda alÄ±ndÄ±\n"
        
        return reasoning
    
    def get_interlock_statistics(self) -> Dict:
        """
        Interlock istatistiklerini hesapla.
        
        TEZ: Sistemin gÃ¼venlik performansÄ±nÄ± deÄŸerlendir.
        """
        
        if not self.interlock_history:
            return {
                'total_interlocks': 0,
                'allow_rate': 0.0,
                'deny_rate': 0.0,
                'escalate_rate': 0.0,
                'avg_risk_score': 0.0
            }
        
        total = len(self.interlock_history)
        
        allows = sum(1 for h in self.interlock_history if h['decision'] == InterlockDecision.ALLOW)
        denies = sum(1 for h in self.interlock_history if h['decision'] == InterlockDecision.DENY)
        escalates = sum(1 for h in self.interlock_history if h['decision'] == InterlockDecision.ESCALATE)
        
        avg_risk = np.mean([h['risk_score'] for h in self.interlock_history])
        
        return {
            'total_interlocks': total,
            'allow_count': allows,
            'deny_count': denies,
            'escalate_count': escalates,
            'allow_rate': allows / total,
            'deny_rate': denies / total,
            'escalate_rate': escalates / total,
            'avg_risk_score': avg_risk
        }
    
    def format_interlock_report(self, report: Dict) -> str:
        """Interlock raporunu formatla."""
        
        output = "\n" + "=" * 70
        output += "\nðŸ”’ XSM INTERLOCK RAPORU (TEZ 4.5.3)"
        output += "\n" + "=" * 70
        
        if not report['interlock_triggered']:
            output += "\nâœ“ Interlock tetiklenmedi (Ã§atÄ±ÅŸma yok)"
            return output + "\n" + "=" * 70
        
        decision = report['decision']
        
        if decision == InterlockDecision.ALLOW:
            icon = "âœ“"
            status = "Ä°ZÄ°N VERÄ°LDÄ°"
        elif decision == InterlockDecision.DENY:
            icon = "âœ˜"
            status = "ENGELLENDÄ°"
        else:
            icon = "âš "
            status = "YÃœKSELTÄ°LDÄ°"
        
        output += f"\n\n{icon} KARAR: {status}"
        output += f"\n  Risk Skoru: {report['risk_score']:.3f}"
        output += f"\n  GÃ¼ven: {report['confidence']:.2f}"
        output += f"\n\n  XDSS â†’ {report['conflict_summary']['xdss_action']}"
        output += f"\n  OperatÃ¶r â†’ {report['conflict_summary']['operator_action']}"
        output += f"\n  Final Aksiyon â†’ {report['final_action']}"
        
        output += f"\n\nðŸ“Š Risk BileÅŸenleri:"
        rb = report['risk_breakdown']
        output += f"\n  Model GÃ¼venilirliÄŸi: {rb['model_confidence']['risk_score']:.3f}"
        output += f"\n  XAI BelirsizliÄŸi: {rb['xai_uncertainty']['risk_score']:.3f}"
        output += f"\n  OperatÃ¶r PerformansÄ±: {rb['operator_performance']['risk_score']:.3f}"
        output += f"\n  Sistem Drift: {rb['system_drift']['risk_score']:.3f}"
        
        output += "\n" + "=" * 70
        
        return output


# =============================================================================
# DEMO FONKSÄ°YONU
# =============================================================================

def demo_xsm_interlock():
    """XSM Interlock demo."""
    
    print("\n" + "ðŸŽ® " + "=" * 66)
    print("XSM INTERLOCK (GÃœVENLÄ°K KÄ°LÄ°DÄ°) DEMO - TEZ 4.5.3")
    print("=" * 70)
    
    from conflict_detector import ConflictDetector, ConflictSeverity
    
    interlock = XSMInterlock(verbose=False)
    detector = ConflictDetector(verbose=False)
    
    # Test senaryolarÄ±
    scenarios = [
        {
            "name": "DÃœÅžÃœK RÄ°SK - ALLOW",
            "xdss": "CHECK",
            "operator": "CONTINUE",
            "xdss_conf": 0.65,
            "operator_conf": 0.80,
            "model_prob": 0.45,
            "operator_profile": {
                'experience_years': 8.0,
                'historical_accuracy': 0.92
            },
            "shap_std": 0.05
        },
        {
            "name": "YÃœKSEK RÄ°SK - DENY",
            "xdss": "STOP",
            "operator": "CONTINUE",
            "xdss_conf": 0.90,
            "operator_conf": 0.60,
            "model_prob": 0.88,
            "operator_profile": {
                'experience_years': 2.0,
                'historical_accuracy': 0.70
            },
            "shap_std": 0.20
        },
        {
            "name": "ORTA RÄ°SK - ESCALATE",
            "xdss": "CHECK",
            "operator": "STOP",
            "xdss_conf": 0.60,
            "operator_conf": 0.55,
            "model_prob": 0.62,
            "operator_profile": {
                'experience_years': 5.0,
                'historical_accuracy': 0.82
            },
            "shap_std": 0.12
        }
    ]
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\n{'='*70}")
        print(f"SENARYO {i}: {scenario['name']}")
        print(f"{'='*70}")
        
        # Ã‡atÄ±ÅŸma tespit
        conflict = detector.detect_conflict(
            xdss_action=scenario['xdss'],
            operator_action=scenario['operator'],
            xdss_confidence=scenario['xdss_conf'],
            operator_confidence=scenario['operator_conf'],
            model_prob=scenario['model_prob']
        )
        
        # Dummy SHAP ve features
        shap_values = np.random.randn(50) * scenario['shap_std']
        feature_values = np.random.randn(50)
        
        # Interlock kararÄ±
        interlock_report = interlock.interlock_decision(
            conflict_report=conflict,
            model_prob=scenario['model_prob'],
            xdss_confidence=scenario['xdss_conf'],
            operator_profile=scenario['operator_profile'],
            shap_values=shap_values,
            feature_values=feature_values,
            xsm_anomaly_report=None
        )
        
        print(interlock.format_interlock_report(interlock_report))
    
    # Ä°statistikler
    stats = interlock.get_interlock_statistics()
    print(f"\n{'='*70}")
    print("GENEL Ä°STATÄ°STÄ°KLER")
    print(f"{'='*70}")
    print(f"Toplam Interlock: {stats['total_interlocks']}")
    print(f"ALLOW OranÄ±: {stats['allow_rate']:.1%}")
    print(f"DENY OranÄ±: {stats['deny_rate']:.1%}")
    print(f"ESCALATE OranÄ±: {stats['escalate_rate']:.1%}")
    print(f"Ortalama Risk: {stats['avg_risk_score']:.3f}")
    
    print("\n" + "=" * 70)
    print("âœ” Demo tamamlandÄ±!")


if __name__ == "__main__":
    demo_xsm_interlock()